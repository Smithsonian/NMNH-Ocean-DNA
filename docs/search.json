[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Here you can find documentation on best practices, data management, utility scripts, and data analysis pipelines."
  },
  {
    "objectID": "qmd/utilityScripts/batchRenameFiles.html",
    "href": "qmd/utilityScripts/batchRenameFiles.html",
    "title": "Batch rename files",
    "section": "",
    "text": "Batch rename files\nScript name: batchRenameFiles.sh\nSource code\nScript to quickly rename many files. Can replace all (-m full) or part (-m partial) of the file names in a target directory.\nRequires the util-linux rename tool.\n\n\n\n\n\n\nWarning\n\n\n\nPLEASE consider making a backup of the target directory before running this script\n\n\nHelp documentation:\nSyntax: batchRenameFiles.sh [-h|d|t|m]\nOptions:\nh     Print this Help\nd     Directory containing files to rename\nt     Tab-delimited txt file with two columns:\n        First column: old file names or old strings in file names\n        Second column: new file names or new strings in file names\nm     File rename mode [full|partial]\n\nThis script requires UNIX line endings for the -t names table. If you created your names table using Excel or a Windows computer, it may have DOS line endings. You can easily convert your table to the correct format using dos2unix.\n\nFull replacement mode example:\n# download the script\nwget https://raw.githubusercontent.com/dmacguigan/SI-Ocean-DNA/refs/heads/main/scripts/utils/batchRenameFiles.sh\n# make a test directory\nmkdir full_test\n# add some empty test files\ntouch full_test/S1.txt full_test/S2.txt full_test/S3.txt\n# print contents of the test directory\nls -l full_test\n# create a tab-delimited table of old and new file names\necho -e \"S1.txt\\tsample1.text\" &gt; names.txt\necho -e \"S2.txt\\tsample2.text\" &gt;&gt; names.txt\necho -e \"S3.txt\\tsample3.text\" &gt;&gt; names.txt\n# check the table format\ncat names.txt\n# run the script\nbash batchRenameFiles.sh -m full -d ./full_test -t names.txt\n# print contents of the test directory\nls -l full_test\nPartial replacement mode example:\n\n\n\n\n\n\nWarning\n\n\n\nPartial replacement mode may fail if strings to be replaced are nested. For example, if you want to replace “s_1” with “s_A” and “s_10” with “s_B”, you will end up with “s_A” and “s_A0”, because “s_1” is nested in “s_10”.\n\n\n# download the script\nwget https://raw.githubusercontent.com/dmacguigan/SI-Ocean-DNA/refs/heads/main/scripts/utils/batchRenameFiles.sh\n# make a test directory\nmkdir partial_test\n# add some empty test files\ntouch partial_test/S1.txt partial_test/S2.txt partial_test/S3.txt partial_test/S1_S3.txt\n# print contents of the test directory\nls -l partial_test\n# create a tab-delimited table of old and new file names\necho -e \"S1\\tsample1\" &gt; names.txt\necho -e \"S2\\tsample2\" &gt;&gt; names.txt\necho -e \"S3\\tsample3\" &gt;&gt; names.txt\n# check the table format\ncat names.txt\n# run the script\nbash batchRenameFiles.sh -m partial -d ./partial_test -t names.txt\n# print contents of the test directory\nls -l partial_test",
    "crumbs": [
      "Utility Scripts",
      "Batch rename files"
    ]
  },
  {
    "objectID": "qmd/utilityScripts/recursiveReplaceStrings.html",
    "href": "qmd/utilityScripts/recursiveReplaceStrings.html",
    "title": "Recursive replace strings",
    "section": "",
    "text": "Recursive replace strings\nScript name: recursiveReplaceStrings.sh\nSource code\n\n\n\n\n\n\nWarning\n\n\n\nPLEASE consider making a backup of the target directory before running this script",
    "crumbs": [
      "Utility Scripts",
      "Recursive replace strings"
    ]
  },
  {
    "objectID": "qmd/hydraScripts/Go_fetch.html",
    "href": "qmd/hydraScripts/Go_fetch.html",
    "title": "go_fetch - download organelle or ribosomal sequences from GenBank",
    "section": "",
    "text": "go_fetch - download organelle or ribosomal sequences from GenBank\n\n\n\n\n\n\nNote\n\n\n\nAISO refers to a script format with 4 required sections: ABOUT, INPUTS, SCRIPT, and OUTPUTS. The user should only need to modify the INPUTS section of the script\n\n\nScript name: AISO_go_fetch.sh\nSource code\nThis script relies on go_fetch",
    "crumbs": [
      "Hydra Analysis Scripts",
      "go_fetch - download organelle or ribosomal sequences from GenBank"
    ]
  },
  {
    "objectID": "qmd/bestpractices.html",
    "href": "qmd/bestpractices.html",
    "title": "Naming conventions",
    "section": "",
    "text": "FASTQ and FASTA files contain biological sequence data, usually nucleotide or amino acid sequences. FASTQ files contain sequence quality information (for example, Phred/Q scores), while FASTA files contain only the sequence.\nFor sequence data generated by the Ocean DNA genome skimming project, it is helpful to have a universal format for file names. This will facilitate downstream file parsing and data management.\nIdeas for required fields: - Voucher/Catalog ID - Taxonomic ID (Family-Genus-Species?), no abbreviations - anything else?\nNeed to consider the issue of when the same sample is sequenced twice. Include a unique identifier based on sequencing batch, plate, and well?\nNO SPACES in file name. Use consistent delimiter (underscore? period? dash?) to separate fields in the file name. Delimiter must NOT be used within the fields. If a field is unknown for a specific sample, insert NA, do not skip the field.\nExample: NMNH-12345_Percidae-Etheostoma-olmstedi_OtherStuff.fastq.gz\nWhy is this helpful? Let’s imagine you wanted to create a table to species names from a recent sequencing run. With a consistent naming scheme for your files, it’s easy!\n# print list of unique species in my FASTQ files\nfind /PATH/TO/MY/DIRECTORY/*.fastq.gz -printf \"%f\\n\" | cut -f2 -d\"_\" | cut -f2,3 -d \"-\" | sort | uniq\nPlease keep FASTQ/A files gzip compressed to minimize disk space.\nCompress a file: gzip fileName.fastq\nDecompress a file (if needed): gunzip fileName.fastq.gz",
    "crumbs": [
      "Best Practices",
      "Naming conventions"
    ]
  },
  {
    "objectID": "qmd/bestpractices.html#fastqa-files---work-in-progress",
    "href": "qmd/bestpractices.html#fastqa-files---work-in-progress",
    "title": "Naming conventions",
    "section": "",
    "text": "FASTQ and FASTA files contain biological sequence data, usually nucleotide or amino acid sequences. FASTQ files contain sequence quality information (for example, Phred/Q scores), while FASTA files contain only the sequence.\nFor sequence data generated by the Ocean DNA genome skimming project, it is helpful to have a universal format for file names. This will facilitate downstream file parsing and data management.\nIdeas for required fields: - Voucher/Catalog ID - Taxonomic ID (Family-Genus-Species?), no abbreviations - anything else?\nNeed to consider the issue of when the same sample is sequenced twice. Include a unique identifier based on sequencing batch, plate, and well?\nNO SPACES in file name. Use consistent delimiter (underscore? period? dash?) to separate fields in the file name. Delimiter must NOT be used within the fields. If a field is unknown for a specific sample, insert NA, do not skip the field.\nExample: NMNH-12345_Percidae-Etheostoma-olmstedi_OtherStuff.fastq.gz\nWhy is this helpful? Let’s imagine you wanted to create a table to species names from a recent sequencing run. With a consistent naming scheme for your files, it’s easy!\n# print list of unique species in my FASTQ files\nfind /PATH/TO/MY/DIRECTORY/*.fastq.gz -printf \"%f\\n\" | cut -f2 -d\"_\" | cut -f2,3 -d \"-\" | sort | uniq\nPlease keep FASTQ/A files gzip compressed to minimize disk space.\nCompress a file: gzip fileName.fastq\nDecompress a file (if needed): gunzip fileName.fastq.gz",
    "crumbs": [
      "Best Practices",
      "Naming conventions"
    ]
  },
  {
    "objectID": "qmd/dataManagementScripts/DNA_QC.html",
    "href": "qmd/dataManagementScripts/DNA_QC.html",
    "title": "DNA sequence data quality control",
    "section": "",
    "text": "Script name: run_DNA_QC.sh\nSource code\nScript to generate QC reports for many DNA FASTQ files. Useful to check the quality of a sequencing run prior to downstream analyses.\nThis script was written specifically for the Smithsonian Hydra cluster, but could be modified to work for other computing environments. It uses FastQC and MultiQC to generate reports. It also performs default fastp filtering and generates post-filtering reports.\n\n\nFirst, you need to download and install Nextflow. On Hydra, run the following commands.\n# Nextflow installation instructions from https://www.nextflow.io/docs/latest/install.html\ncd ~\nmodule load tools/java/21.0.2\ncurl -s https://get.nextflow.io | bash # install Nextflow\nchmod +x nextflow # make Nextflow executable\nmkdir ~/bin # create bin directory, if needed\nmv ~/nextflow ~/bin/nextflow # move nextflow to bin directory\necho 'export PATH=\"${HOME}/bin:${PATH}\"' &gt;&gt; ~/.bashrc # add bin directory to PATH, in case it's not already there\nsource ~/.bashrc\nThis will allow you to run nextflow from anywhere on the cluster (if you have the java 21.0.2 module loaded).\nNext, we need to download the QC scripts.\nmkdir ~/DNA_QC_scripts\ncd ~/DNA_QC_scripts\n# download the Nextflow workflow\nwget https://github.com/dmacguigan/SI-Ocean-DNA/blob/main/scripts/data_management/DNA_QC/DNA_QC.nf\n# download the Nextflow config file\nwget https://github.com/dmacguigan/SI-Ocean-DNA/blob/main/scripts/data_management/DNA_QC/Hydra.nf.config\n\n\n\nDecide where you want to store the QC reports and navigate there on the command line. Then download the run_DNA_QC.sh script. For example:\nmkdir ~/my_project_QC # create a new directory in your home directory\ncd ~/my_project_QC \nwget https://github.com/dmacguigan/SI-Ocean-DNA/blob/main/scripts/data_management/DNA_QC/run_DNA_QC.sh\nNow open run_DNA_QC.sh and modify the RAW_DATA_DIR and READS_SUFFIX variables.\n\nRAW_DATA_DIR: Path to a directory containing the sequence data. All files should all be FASTQ and gzipped (i.e. end in “.fastq.gz”).\nREADS_SUFFIX: The file name suffix linking the forward and reverse reads. For example, if “sampleA” has two paired read files “sampleA_R1.fastq.gz” and “sampleA_R2.fastq.gz”, the suffix would be “_R{1,2}.fastq.gz”.\n\nFinally, run the script.\nbash run_DNA_QC.sh\nOutput will be written to QC_results. To see a summary of all samples, download the HTML files in QC_results/multiqc and open with a web browser.\nIf you have many samples, consider running run_DNA_QC.sh as a batch job with qsub. You will need to use the special workflow manager queue “lTWFM.sq” in order to run Nextflow inside of a batch job.\n\n\n\nYou can change the filtering settings by modifying the shell section of the FASTP process block in the DNA_QC.nf workflow. For example, if you want to trim all reads to a maximum length of 100 bp:\n    shell:\n    '''\n        fastp -i !{reads[0]} \\\n            -I !{reads[1]} \\\n            -o !{reads[0].simpleName}_trimmed.fastq.gz \\\n            -O !{reads[1].simpleName}_trimmed.fastq.gz \\\n            --max_len 100\n    '''\nSee the fastp CLI reference for a complete list of options.",
    "crumbs": [
      "Data Management Scripts",
      "DNA sequence data quality control"
    ]
  },
  {
    "objectID": "qmd/dataManagementScripts/DNA_QC.html#setup",
    "href": "qmd/dataManagementScripts/DNA_QC.html#setup",
    "title": "DNA sequence data quality control",
    "section": "",
    "text": "First, you need to download and install Nextflow. On Hydra, run the following commands.\n# Nextflow installation instructions from https://www.nextflow.io/docs/latest/install.html\ncd ~\nmodule load tools/java/21.0.2\ncurl -s https://get.nextflow.io | bash # install Nextflow\nchmod +x nextflow # make Nextflow executable\nmkdir ~/bin # create bin directory, if needed\nmv ~/nextflow ~/bin/nextflow # move nextflow to bin directory\necho 'export PATH=\"${HOME}/bin:${PATH}\"' &gt;&gt; ~/.bashrc # add bin directory to PATH, in case it's not already there\nsource ~/.bashrc\nThis will allow you to run nextflow from anywhere on the cluster (if you have the java 21.0.2 module loaded).\nNext, we need to download the QC scripts.\nmkdir ~/DNA_QC_scripts\ncd ~/DNA_QC_scripts\n# download the Nextflow workflow\nwget https://github.com/dmacguigan/SI-Ocean-DNA/blob/main/scripts/data_management/DNA_QC/DNA_QC.nf\n# download the Nextflow config file\nwget https://github.com/dmacguigan/SI-Ocean-DNA/blob/main/scripts/data_management/DNA_QC/Hydra.nf.config",
    "crumbs": [
      "Data Management Scripts",
      "DNA sequence data quality control"
    ]
  },
  {
    "objectID": "qmd/dataManagementScripts/DNA_QC.html#running-the-script",
    "href": "qmd/dataManagementScripts/DNA_QC.html#running-the-script",
    "title": "DNA sequence data quality control",
    "section": "",
    "text": "Decide where you want to store the QC reports and navigate there on the command line. Then download the run_DNA_QC.sh script. For example:\nmkdir ~/my_project_QC # create a new directory in your home directory\ncd ~/my_project_QC \nwget https://github.com/dmacguigan/SI-Ocean-DNA/blob/main/scripts/data_management/DNA_QC/run_DNA_QC.sh\nNow open run_DNA_QC.sh and modify the RAW_DATA_DIR and READS_SUFFIX variables.\n\nRAW_DATA_DIR: Path to a directory containing the sequence data. All files should all be FASTQ and gzipped (i.e. end in “.fastq.gz”).\nREADS_SUFFIX: The file name suffix linking the forward and reverse reads. For example, if “sampleA” has two paired read files “sampleA_R1.fastq.gz” and “sampleA_R2.fastq.gz”, the suffix would be “_R{1,2}.fastq.gz”.\n\nFinally, run the script.\nbash run_DNA_QC.sh\nOutput will be written to QC_results. To see a summary of all samples, download the HTML files in QC_results/multiqc and open with a web browser.\nIf you have many samples, consider running run_DNA_QC.sh as a batch job with qsub. You will need to use the special workflow manager queue “lTWFM.sq” in order to run Nextflow inside of a batch job.",
    "crumbs": [
      "Data Management Scripts",
      "DNA sequence data quality control"
    ]
  },
  {
    "objectID": "qmd/dataManagementScripts/DNA_QC.html#optional-adjust-filtering",
    "href": "qmd/dataManagementScripts/DNA_QC.html#optional-adjust-filtering",
    "title": "DNA sequence data quality control",
    "section": "",
    "text": "You can change the filtering settings by modifying the shell section of the FASTP process block in the DNA_QC.nf workflow. For example, if you want to trim all reads to a maximum length of 100 bp:\n    shell:\n    '''\n        fastp -i !{reads[0]} \\\n            -I !{reads[1]} \\\n            -o !{reads[0].simpleName}_trimmed.fastq.gz \\\n            -O !{reads[1].simpleName}_trimmed.fastq.gz \\\n            --max_len 100\n    '''\nSee the fastp CLI reference for a complete list of options.",
    "crumbs": [
      "Data Management Scripts",
      "DNA sequence data quality control"
    ]
  },
  {
    "objectID": "qmd/dataManagementScripts/raw_sequence_validate.html",
    "href": "qmd/dataManagementScripts/raw_sequence_validate.html",
    "title": "Validate Hydra Store raw sequence data and metadata",
    "section": "",
    "text": "Validate Hydra Store raw sequence data and metadata\nScript name: validate_seq_data.py or validate_seq_data.sh\npython source code\nbash source code\nValidates Ocean DNA raw sequence data against its corresponding metadata. The python script is faster than the bash script.\nTo download the script:\n# download python script\nwget https://github.com/dmacguigan/SI-Ocean-DNA/blob/main/scripts/data_management/raw_sequence_validate/validate_seq_data.py\n# download bash script\nwget https://github.com/dmacguigan/SI-Ocean-DNA/blob/main/scripts/data_management/raw_sequence_validate/validate_seq_data.sh\nRun python validate_seq_data.py -h or bash validate_seq_data.sh -h to print the help documentation.\nDESCRIPTION:\n    Validates Ocean DNA raw sequence data against its corresponding metadata.\n    This script checks for correct naming, file existence, and ensures that\n    the contents of the metadata file and sequence data directory match.\n\nARGUMENTS:\n  MAP_FILE\n      Path to a text file mapping metadata to sequence data directories.\n      It requires a header row (which is ignored). Each subsequent line\n      should contain two space-separated columns:\n\n      Column 1: The metadata CSV filename.\n                - Must be in \"/store/public/oceandna/raw_sequence_metadata\"\n                - Must end with \"_mapfile.csv\"\n                - Its header must start with \"ID,R1,R2,Taxon,UniqueID\"\n\n      Column 2: The raw sequence data directory name.\n                - Must be in \"/store/public/oceandna/raw_sequence_data\"\n                - Must contain one or more .fastq.gz files\n\nOPTIONS:\n  -h, --help\n      Display this help message and exit.\nExample MAP_FILE.",
    "crumbs": [
      "Data Management Scripts",
      "Validate Hydra Store raw sequence data and metadata"
    ]
  },
  {
    "objectID": "qmd/datamanagement.html",
    "href": "qmd/datamanagement.html",
    "title": "Data management workflow",
    "section": "",
    "text": "Data management workflow\nThe following is a proposed data management guide for SI Ocean DNA sequence data. This workflow was designed for genome skimming datasets, but could be adapted for other project types.\n\n\n\n\n\n\nImportant\n\n\n\nPlease see the README.md the Ocean DNA Hydra Store directory for details about where to upload raw data and how to name files and directories.\n\n\n\n\n\n\n\ngraph TD;\n\n  GenoHub[**GenoHub**\nDemultiplexed and compressed sequence reads in FASTQ format. Files should end in “.fastq.gz” or “.fq.gz”]\n  Metadata[**Metadata CSV**\nInformation for all samples in the GenoHub project. Must include the following columns:\n***ID:*** GenoHub sample name\n***R1:*** read 1 FASTQ file name\n***R2:*** read 2 FASTQ file name\n***Taxon:*** your best guess at taxonomic assignment\n***UniqID:*** unique identifier linked to a voucher/tissue sample\n  ]\n  Analyses(Run quality/adapter trimming, mitogenome assembly, etc)\n  Scratch[(**Hydra Scratch**\n/scratch/nmnh_ocean_dna\n40 TB. Not backed up, no automatic file purging.)]\n  Store[(**Hydra Store**\n/store/public/oceandna\n40 TB. Not backed up, no automatic file purging. For large raw data files and inactive projects. Drive system is slower, can't be used for active analysis)]\n  PDrive[(**P Drive**\nP:&bsol;NMNH-OCEAN-DNA\n80 TB. Incrementally backed up daily, fully backed up weekly. Only accessible from SI computers.)]\n  \n  Move1[download raw FASTQ files]  \n  Move3[copy important results]\n  Move4[Dan M. runs monthly and on-demand backup]\n\n  Metadata--&gt;Store\n  GenoHub--&gt;Move1\n  Move1--&gt;Store\n  Move1--&gt;Scratch\n  subgraph \" \"\n    Scratch--&gt;Analyses\n    Analyses--&gt;Move3\n    Move3--&gt;Store\n  end\n  Store--&gt;Move4\n  Move4--&gt;PDrive\n\n  classDef process stroke:black,color:white,fill:#159BD7,stroke-dasharray: 5 5\n  classDef storage stroke:black,color:white,fill:#159BD7\n  classDef ccr stroke:black,color:white,fill:#159BD7\n\n  class Rename,Analyses,Move1,Move2,Move3,Move4 process\n  class Metadata,GenoHub,Scratch,Store,PDrive storage\n\n  click Rename \"bestpractices.html\"\n\n  linkStyle default stroke:grey, stroke-width:4px",
    "crumbs": [
      "Data Management",
      "Data management workflow"
    ]
  },
  {
    "objectID": "qmd/hydraScripts/BLAST_18s_28s.html",
    "href": "qmd/hydraScripts/BLAST_18s_28s.html",
    "title": "BLAST - find 18s & 28s in genome assembly",
    "section": "",
    "text": "Script name: BLAST_18s-28s_hydra.sh\nsource code\nThis script is meant to help identify and extract contigs/scaffolds containing the 18s and 28s genes.\nTo download the script:\nwget https://raw.githubusercontent.com/dmacguigan/SI-Ocean-DNA/refs/heads/main/scripts/Hydra/BLAST_Hydra/BLAST_18s-28s_hydra.sh\nTry running bash batchRenameFiles.sh -h to print the help documentation.\nScript to find and rename contigs/scaffolds containing\n18s and/or 28s genes\n\nauthor: Dan MacGuigan\ncontact: macguigand@si.edu\n\nOptions:\nc   FASTA file containing genomics scaffolds or contigs\ni   sample ID, will be used to name resulting files and BLAST hits\ns   FASTA file containing query 18s sequence\nl   FASTA file containing query 28s sequence\nh   Print this Help\n\nUsage:\nbash BLAST_18s-28s_hydra.sh -c my_contigs.fasta -i my_sample_ID -s my_18s.fasta -l my_28s.fasta\n\n\n\nScript name: BLAST_job.sh\nsource code\nThis script is a wrapper for BLAST_18s-28s_hydra.sh, allowing you analyze multiple genome assemblies.\nTo download the script:\nwget https://raw.githubusercontent.com/dmacguigan/SI-Ocean-DNA/refs/heads/main/scripts/Hydra/BLAST_Hydra/BLAST_job.sh\nYou will then need to modify the INPUTS section.\n# INPUTS ################################################\n\n# working directory containing contig/scaffold FASTA files\nDIR=\"/pool/public/genomics/macguigand/BLAST_testing/scaffolds\"\n\n# FASTA file suffix (e.g. \"fasta\", \"fa\", \"fas\")\n# must be the same for all files in DIR\nSUFFIX=\"fasta\"\n\n# full path to 18s and 28s query sequences\nrRNA_S=\"/pool/public/genomics/macguigand/BLAST_testing/18s.fasta\"\nrRNA_L=\"/pool/public/genomics/macguigand/BLAST_testing/28s.fasta\"\n\n# full path to your copy of the BLAST_18s-28s_hydra.sh script\nBLAST_SCRIPT=\"/pool/public/genomics/macguigand/BLAST_testing/BLAST_18s-28s_hydra.sh\"\nRunning qsub BLAST_job.sh will submit the script to the cluster’s job scheduler.\nOnce complete, BLAST hits will be written to a new folder BLAST_hits within DIR.",
    "crumbs": [
      "Hydra Analysis Scripts",
      "BLAST - find 18s & 28s in genome assembly"
    ]
  },
  {
    "objectID": "qmd/hydraScripts/BLAST_18s_28s.html#blast_18s-28s_hydra.sh",
    "href": "qmd/hydraScripts/BLAST_18s_28s.html#blast_18s-28s_hydra.sh",
    "title": "BLAST - find 18s & 28s in genome assembly",
    "section": "",
    "text": "Script name: BLAST_18s-28s_hydra.sh\nsource code\nThis script is meant to help identify and extract contigs/scaffolds containing the 18s and 28s genes.\nTo download the script:\nwget https://raw.githubusercontent.com/dmacguigan/SI-Ocean-DNA/refs/heads/main/scripts/Hydra/BLAST_Hydra/BLAST_18s-28s_hydra.sh\nTry running bash batchRenameFiles.sh -h to print the help documentation.\nScript to find and rename contigs/scaffolds containing\n18s and/or 28s genes\n\nauthor: Dan MacGuigan\ncontact: macguigand@si.edu\n\nOptions:\nc   FASTA file containing genomics scaffolds or contigs\ni   sample ID, will be used to name resulting files and BLAST hits\ns   FASTA file containing query 18s sequence\nl   FASTA file containing query 28s sequence\nh   Print this Help\n\nUsage:\nbash BLAST_18s-28s_hydra.sh -c my_contigs.fasta -i my_sample_ID -s my_18s.fasta -l my_28s.fasta",
    "crumbs": [
      "Hydra Analysis Scripts",
      "BLAST - find 18s & 28s in genome assembly"
    ]
  },
  {
    "objectID": "qmd/hydraScripts/BLAST_18s_28s.html#blast_job.sh",
    "href": "qmd/hydraScripts/BLAST_18s_28s.html#blast_job.sh",
    "title": "BLAST - find 18s & 28s in genome assembly",
    "section": "",
    "text": "Script name: BLAST_job.sh\nsource code\nThis script is a wrapper for BLAST_18s-28s_hydra.sh, allowing you analyze multiple genome assemblies.\nTo download the script:\nwget https://raw.githubusercontent.com/dmacguigan/SI-Ocean-DNA/refs/heads/main/scripts/Hydra/BLAST_Hydra/BLAST_job.sh\nYou will then need to modify the INPUTS section.\n# INPUTS ################################################\n\n# working directory containing contig/scaffold FASTA files\nDIR=\"/pool/public/genomics/macguigand/BLAST_testing/scaffolds\"\n\n# FASTA file suffix (e.g. \"fasta\", \"fa\", \"fas\")\n# must be the same for all files in DIR\nSUFFIX=\"fasta\"\n\n# full path to 18s and 28s query sequences\nrRNA_S=\"/pool/public/genomics/macguigand/BLAST_testing/18s.fasta\"\nrRNA_L=\"/pool/public/genomics/macguigand/BLAST_testing/28s.fasta\"\n\n# full path to your copy of the BLAST_18s-28s_hydra.sh script\nBLAST_SCRIPT=\"/pool/public/genomics/macguigand/BLAST_testing/BLAST_18s-28s_hydra.sh\"\nRunning qsub BLAST_job.sh will submit the script to the cluster’s job scheduler.\nOnce complete, BLAST hits will be written to a new folder BLAST_hits within DIR.",
    "crumbs": [
      "Hydra Analysis Scripts",
      "BLAST - find 18s & 28s in genome assembly"
    ]
  },
  {
    "objectID": "qmd/hydraScripts/GetOrganelle.html",
    "href": "qmd/hydraScripts/GetOrganelle.html",
    "title": "GetOrganelle - targeted organelle assembly",
    "section": "",
    "text": "GetOrganelle - targeted organelle assembly\n\n\n\n\n\n\nNote\n\n\n\nAISO refers to a script format with 4 required sections: ABOUT, INPUTS, SCRIPT, and OUTPUTS. The user should only need to modify the INPUTS section of the script\n\n\nScript name: AISO_GetOrganelle_Hydra.sh\nSource code",
    "crumbs": [
      "Hydra Analysis Scripts",
      "GetOrganelle - targeted organelle assembly"
    ]
  },
  {
    "objectID": "qmd/utilityScripts/validate_biosample_taxonomy.html",
    "href": "qmd/utilityScripts/validate_biosample_taxonomy.html",
    "title": "Validate BioProject taxonomy",
    "section": "",
    "text": "Validate BioProject taxonomy\nScript name: validate_biosample_taxonomy.py\nSource code\nThis python script checks the taxonomy between all GenBank nucleotide records and associated BioSamples in a specific BioProject. It verifies that the ORGANISM field of the GenBank record matches the BioSample OrganismName. Mismatches are written to a CSV file, taxon_mismatches.csv.\nIf a GenBank nucleotide record does not have an associated BioSample, it the GenBank accession number is written to the file GenBank_records_no_BioSample.txt.\nThis script has the following dependencies:\n\npython 3\nbiopython\n\nThis could be easily set up in a conda environment. For example:\nconda create --name biopython conda-forge::biopython\nThis script takes 3 arguments\n\nA NCBI BioProject number (e.g. PRJNA720393)\nYour email address, required for Entrez tools\nYour NCBI API key (instructions to generate a key)\n\nExample usage:\npython validate_biosample_taxonomy.py \"PRJNXXXXX\" \"YOUR_EMAIL\" \"YOUR_NCBI_API_KEY\"\n\n\n\n\n\n\nWarning\n\n\n\nNCBI Entrez Programming Utilities (E-utilities) are limited to 10,000 queries at a time (retmax = 10000). If your BioProject contains more than 10,000 GenBank records, this script will not work.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis script may randomly crash. This is usually due to a http request timeout. Try restarting the script if this happens.",
    "crumbs": [
      "Utility Scripts",
      "Validate BioProject taxonomy"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SI Ocean DNA",
    "section": "",
    "text": "Welcome to the SI Ocean DNA landing page."
  }
]